<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Units 5–7 MCQs</title>
<style>
  body{font-family:Arial,Helvetica,sans-serif;margin:0;padding:1.5rem;background:#f9fafb;color:#111}
  h1{text-align:center;font-size:1.9rem;margin:0 0 0.5rem;font-weight:700}
  .note{background:#e2e8f0;color:#334155;border-radius:6px;padding:0.75rem 1rem;margin:0 auto 1.25rem;max-width:45rem;font-size:0.9rem}
  .question{background:#e06e16;border:1px solid #e06e16;border-radius:8px;padding:1rem;max-width:45rem;margin:0 auto 1rem}
  .question h3{margin:0 0 0.75rem;font-size:1.05rem;color:#1e293b}
  label{display:block;margin:0.25rem 0;cursor:pointer}
  input[type="radio"] { accent-color:#e06e16; }  .feedback{margin-top:0.75rem;font-weight:600}
  .correct{color:#059669}
  .incorrect{color:#dc2626}
  @media(prefers-color-scheme:dark){body{background:#0f172a;color:#e2e8f0}.question{background:#1e293b;border-color:#334155}.note{background:#334155;color:#e2e8f0}}
</style>
</head>
<body>
<h1>Units 5–7 MCQs</h1>
<div class="note">The questions were generated by AI</div>

<script>
const qData = [
  // ------------------------- Unit 5 – Interpolation (15) -------------------------
  {t:"Newton’s Polynomial",q:"What feature of Newton’s divided-difference polynomial makes it ideal for exploring polynomial orders?",o:["It requires equally spaced points","It allows sequential addition of higher-order terms","It eliminates round-off errors","It uses fewer data points than Lagrange"],a:1,e:"Sec. 18.1.5 (UNIT 5 Book.pdf) notes that Newton’s polynomial (Eq. 18.7) supports adding terms sequentially, enabling efficient order exploration (Example 18.5)."},
  {t:"Lagrange Polynomial",q:"Why is the Lagrange polynomial often preferred for a single, fixed-order interpolation?",o:["It guarantees zero error for polynomials","It avoids computing divided differences","It handles oscillatory functions better","It requires fewer function evaluations"],a:1,e:"Sec. 18.2 states that Lagrange polynomials (Eq. 18.20) are simpler to code for fixed orders by avoiding divided differences, unlike Newton’s method (Example 18.6)."},
  {t:"Error Estimation",q:"In Example 18.4, the error estimate for a quadratic Newton polynomial uses the third divided difference to approximate:",o:["The second derivative","The third derivative scaled by a factorial","The exact function value","The first divided difference"],a:1,e:"Eq. 18.18 shows the error involves the (n+1)-th divided difference, approximating f^(n+1)(ξ)/(n+1)!; for n=2, this is the third divided difference (Sec. 18.1.4)."},
  {t:"Polynomial Behavior",q:"Why did the fourth-order Lagrange polynomial in Example 18.7 overestimate the parachutist’s velocity at t=10?",o:["Data points were unequally spaced","High-order polynomials introduced oscillations","The function was discontinuous","Round-off errors dominated"],a:1,e:"Sec. 18.4 and Fig. 18.12a show high-order polynomials are ill-conditioned, causing oscillations that overshoot trends in noisy data (Example 18.7)."},
  {t:"Divided Differences",q:"How is the second divided difference f[x₂, x₁, x₀] computed in Newton’s interpolation?",o:["(f(x₂) - f(x₁))/(x₂ - x₁) - (f(x₁) - f(x₀))/(x₁ - x₀)","(f[x₂, x₁] - f[x₁, x₀])/(x₂ - x₀)","(f(x₂) - 2f(x₁) + f(x₀))/(x₂ - x₀)²","(f(x₂) + f(x₁) - f(x₀))/(x₂ - x₁)"],a:1,e:"Eq. 18.13 defines the second divided difference as the difference of first divided differences divided by x₂ - x₀ (Example 18.3)."},
  {t:"Point Selection",q:"In Example 18.5, including x=1.5 significantly reduced the error in interpolating ln 2 because:",o:["It was the closest point to x=2","It reduced the polynomial degree","It eliminated round-off errors","It ensured equal spacing"],a:0,e:"Sec. 18.1.5 and Fig. 18.9 show that points closer to x=2 (e.g., x=1.5) minimize the error term ∏(x - xᵢ) (Eq. 18.17)."},
  {t:"Algorithm Efficiency",q:"The Newton interpolation algorithm (Fig. 18.7) is efficient due to:",o:["Recursive computation of divided differences","Avoidance of all multiplications","Use of a single data point","Guaranteed exact results"],a:0,e:"Sec. 18.1.5 highlights that the algorithm uses the recursive nature of divided differences (Fig. 18.5) for efficiency."},
  {t:"Polynomial Coefficients",q:"Why is solving linear equations (Eq. 18.26) for polynomial coefficients often avoided?",o:["It is too slow for low-degree polynomials","The system is ill-conditioned for high n","It requires unequally spaced points","It cannot handle noisy data"],a:1,e:"Sec. 18.3 warns that systems like Eq. 18.26 are ill-conditioned for large n, leading to inaccurate coefficients."},
  {t:"Error Convergence",q:"For a cubic Newton polynomial interpolating a smooth function, adding a fourth point reduces the error by a factor of:",o:["h","h²","h³","h⁴"],a:0,e:"The error is O(h^(n+1)); for n=3, adding a point increases n to 4, reducing error from O(h⁴) to O(h⁵), a factor of h (Sec. 18.1.4)."},
  {t:"Practical Application",q:"Why was a first- or second-order polynomial recommended for the parachutist data in Example 18.7?",o:["Higher orders were too accurate","Lower orders avoided overshooting trends","Data required unequally spaced points","High orders were too costly"],a:1,e:"Fig. 18.12 shows higher-order polynomials overshoot trends due to ill-conditioning, making lower orders reliable (Sec. 18.4)."},
  {t:"Data Flexibility",q:"Unlike many differentiation and integration methods, Newton’s interpolation polynomial:",o:["Requires equally spaced points","Handles unequally spaced points","Cannot use more than three points","Must use central differences"],a:1,e:"Sec. 18.1.3 notes that Newton’s polynomial (Eq. 18.15) works with unequally spaced points."},
  {t:"Error Sensitivity",q:"Why do high-order polynomials amplify errors in noisy data (Example 18.7)?",o:["They reduce the step size h","Their coefficients are sensitive to small changes","They require analytical derivatives","They eliminate truncation errors"],a:1,e:"Sec. 18.4 explains that high-order polynomials are ill-conditioned, making coefficients sensitive to noise."},
  {t:"Algorithm Design",q:"The Newton interpolation algorithm (Fig. 18.7) estimates errors by:",o:["Computing differences between successive polynomial orders","Calculating analytical derivatives","Doubling the step size h","Ignoring higher-order terms"],a:0,e:"Eq. 18.19 shows the error as R_n = f_(n+1)(x) - f_n(x), computed sequentially (Sec. 18.1.5)."},
  {t:"Point Ordering",q:"In Example 18.5, reordering points to include x=2.5 and x=1.5 improved convergence for ln 2 because:",o:["It reduced polynomial degree","It placed points closer to x=2","It eliminated divided differences","It ensured equal spacing"],a:1,e:"Fig. 18.9 shows points closer to and balanced around x=2 minimize the error term ∏(x - xᵢ) (Sec. 18.1.5)."},

  // ------------------------- Unit 6 – Numerical Differentiation (15) -------------------------
  {t:"Centered Difference",q:"Why does the centered difference formula (Eq. 4.22) have an O(h²) error?",o:["It cancels first-order error terms via symmetry","It uses fewer function evaluations","It assumes a constant second derivative","It doubles the step size h"],a:0,e:"Eq. 4.22 shows that subtracting Taylor expansions cancels odd-order terms (e.g., h f''), leaving an error of O(h²) (Sec. 4.1.3)."},
  {t:"High-Accuracy Formula",q:"The high-accuracy forward difference formula (Eq. 23.4) improves accuracy to O(h²) by:",o:["Incorporating the second derivative approximation","Using central differences","Reducing the step size h","Eliminating all derivatives"],a:0,e:"Sec. 23.1 explains that including the second derivative term (Eq. 4.24) in Eq. 23.2 improves the error to O(h²) (Example 23.1)."},
  {t:"Second Derivative",q:"The centered second derivative formula (Eq. 4.27) has an error of O(h²) because:",o:["It cancels third-order derivative terms","It uses only two points","It assumes a linear function","It requires unequally spaced points"],a:0,e:"Sec. 4.1.3 shows the error is O(h²) due to symmetry canceling lower-order terms in the Taylor expansion."},
  {t:"Noise Sensitivity",q:"Why are finite differences sensitive to noisy data, as noted in Sec. 23.1?",o:["Subtraction amplifies small errors","They require large step sizes","They eliminate truncation errors","They use analytical derivatives"],a:0,e:"Sec. 23.1 warns that subtracting nearly equal values in differences amplifies noise, increasing round-off errors."},
  {t:"Step Size Trade-off",q:"In Example 4.4, halving h from 0.5 to 0.25 for the centered difference:",o:["Quarters the truncation error","Doubles the truncation error","Eliminates round-off errors","Has no effect on accuracy"],a:0,e:"Sec. 4.1.3 notes that the centered difference error is O(h²); halving h reduces error by a factor of 4 (Example 4.4)."},
  {t:"Backward Difference",q:"When is the backward difference formula (Eq. 4.20) most appropriate?",o:["When evaluating near the end of a data set","When points are unequally spaced","When computing second derivatives","When noise is minimal"],a:0,e:"Sec. 4.1.3 and Fig. 4.6b show backward differences use prior points, ideal near the data’s end."},
  {t:"Taylor Derivation",q:"Finite difference formulas are derived by:",o:["Truncating Taylor series expansions","Solving linear equations","Integrating polynomials","Using Lagrange interpolation"],a:0,e:"Sec. 4.1.3 and 23.1 derive formulas like Eq. 4.14 and 23.2 from Taylor series truncations."},
  {t:"Function Evaluations",q:"The high-accuracy centered difference formula in Fig. 23.3 (O(h⁴)) requires how many function values?",o:["2","3","4","5"],a:3,e:"Fig. 23.3 shows the formula uses f(x_(i+2)), f(x_(i+1)), f(x_(i-1)), f(x_(i-2)), totaling 4 points."},
  {t:"Practical Consideration",q:"For an oscillatory function, choosing a small h in finite differences is critical to:",o:["Capture rapid variations accurately","Reduce computational cost","Eliminate round-off errors","Ensure equal spacing"],a:0,e:"Sec. 23.1 implies that large h may miss oscillations, underestimating derivatives."},
  {t:"Boundary Conditions",q:"To approximate f'(x) at the first data point, which formula is most suitable?",o:["Forward difference","Centered difference","Backward difference","Richardson extrapolation"],a:0,e:"Sec. 4.1.3 and Fig. 4.6a show forward differences use available points (x_i, x_(i+1)) at the start."},
  {t:"Error Analysis",q:"In Example 23.1, the centered O(h⁴) formula gave an exact result because:",o:["The function was a fourth-degree polynomial","The step size was doubled","It used unequally spaced points","Round-off errors canceled"],a:0,e:"Sec. 23.1 notes that high-accuracy formulas are exact for polynomials of degree ≤4 (Example 23.1)."},
  {t:"Difference Operators",q:"The symbol ∇ in Eq. 4.20 represents:",o:["Forward difference operator","Backward difference operator","Second derivative operator","Error term"],a:1,e:"Sec. 4.1.3 defines ∇ as the first backward difference in the backward formula."},
  {t:"Higher Derivatives",q:"The forward second derivative formula (Eq. 4.24) requires function values at:",o:["x_i, x_(i+1), x_(i+2)","x_i, x_(i-1), x_(i-2)","x_(i-1), x_i, x_(i+1)","x_i only"],a:0,e:"Eq. 4.24 uses f(x_(i+2)), 2f(x_(i+1)), f(x_i) for the second derivative (Sec. 4.1.3)."},

  // ------------------------- Unit 7 – Numerical Integration (15) -------------------------
  {t:"Trapezoidal Rule",q:"Why is the trapezoidal rule exact for linear functions?",o:["It fits a linear polynomial to the data","It uses central differences","It eliminates round-off errors","It requires three points"],a:0,e:"Sec. 21.1.1 explains that the trapezoidal rule (Eq. 21.4) integrates a linear polynomial exactly (Example 21.1)."},
  {t:"Simpson’s 1/3 Rule",q:"In Example 21.2, Simpson’s 1/3 rule was more accurate than the trapezoidal rule because:",o:["It fits a quadratic polynomial","It uses fewer function evaluations","It assumes constant spacing","It eliminates truncation errors"],a:0,e:"Sec. 21.1.2 notes that Simpson’s 1/3 rule (Eq. 21.7) integrates quadratics exactly, improving accuracy (Example 21.2)."},
  {t:"Error Scaling",q:"In composite Simpson’s 1/3 rule, doubling the number of segments reduces the error by approximately:",o:["2×","4×","8×","16×"],a:3,e:"Sec. 21.2.2 states the error is O(h⁴); halving h (doubling n) reduces error by 2⁴=16 (Example 21.5)."},
  {t:"Simpson’s 3/8 Rule",q:"When is Simpson’s 3/8 rule most useful?",o:["When n is a multiple of 3 but not 2","When data points are unequally spaced","When integrating linear functions","When round-off errors dominate"],a:0,e:"Sec. 21.2.2 notes that Simpson’s 3/8 rule (Eq. 21.13) is used for n divisible by 3 (Example 21.6)."},
  {t:"Function Evaluations",q:"For n=4 segments, how many function evaluations does composite Simpson’s 1/3 rule require?",o:["3","4","5","6"],a:2,e:"Sec. 21.2.2 explains that n segments require n+1 points; for n=4, this is 5 evaluations (Eq. 21.12)."},
  {t:"Error Term",q:"The leading error term for the single-segment trapezoidal rule includes:",o:["h² f'(ξ)","h³ f''(ξ)","h⁴ f'''(ξ)","h⁵ f⁽⁴⁾(ξ)"],a:1,e:"Sec. 21.1.1 states the trapezoidal error is -(h³/12)f''(ξ) (Eq. 21.5)."},
  {t:"Integration Strategy",q:"For n=5 segments, a recommended integration approach is:",o:["Two Simpson’s 1/3 panels plus one Simpson’s 3/8","Trapezoidal rule only","Simpson’s 1/3 across all","Midpoint rule"],a:0,e:"Sec. 21.2.2 suggests mixing Simpson’s 1/3 and 3/8 for odd n (Example 21.6)."},
  {t:"Practical Tip",q:"Why is plotting the integrand recommended before applying composite Simpson’s rule?",o:["To assess smoothness and choose n","To compute derivatives","To ensure equal spacing","To eliminate round-off errors"],a:0,e:"Sec. 21.2.2 implies that visualizing the integrand helps determine segment count for accuracy."},
  {t:"Accuracy Comparison",q:"Compared to the trapezoidal rule, Simpson’s 1/3 rule is more accurate for:",o:["Constant functions","Linear functions","Quadratic functions","Discontinuous functions"],a:2,e:"Sec. 21.1.2 notes that Simpson’s 1/3 is exact for quadratics, unlike trapezoidal (Example 21.2)."},
  {t:"Segment Weighting",q:"In composite Simpson’s 1/3 rule, the first interior point is weighted by:",o:["1","2","4","6"],a:2,e:"Sec. 21.2.2 shows the weighting pattern as 1, 4, 2, 4, …, 1 (Eq. 21.12)."},
  {t:"Error Behavior",q:"For a smooth function, the composite trapezoidal rule’s error is primarily due to:",o:["Round-off errors","Truncation errors","Unequal spacing","Function discontinuities"],a:1,e:"Sec. 21.2.1 notes that the error is O(h²) due to truncation (Eq. 21.11)."},
  {t:"Integration Choice",q:"Simpson’s 1/3 rule requires an even number of segments to:",o:["Ensure symmetry in polynomial fitting","Reduce round-off errors","Allow unequally spaced points","Simplify derivative calculations"],a:0,e:"Sec. 21.2.2 explains that even n ensures quadratic polynomial pairs (Eq. 21.12)."},
  {t:"Computational Cost",q:"When doubling n in composite trapezoidal rule, existing function values:",o:["Can be reused at old points","Must all be recomputed","Reduce accuracy","Require derivative calculations"],a:0,e:"Sec. 21.2.1 notes that doubling n reuses previous points, reducing new evaluations (Example 21.4)."},

  // ------------------------- Mixed Review (5) -------------------------
  {t:"Error Types",q:"What distinguishes truncation error from round-off error across all units?",o:["Truncation arises from finite precision; round-off from series truncation","Truncation from omitting higher terms; round-off from finite precision","Truncation from noisy data; round-off from step size","Both are identical in practice"],a:1,e:"Sec. 4.1 (Unit 6) and 21.1.1 (Unit 7) define truncation as error from omitting terms, round-off from machine precision."},
  {t:"Method Linkage",q:"Finite divided differences are a common tool in:",o:["Interpolation and differentiation","Differentiation and integration","Interpolation and integration","All three methods"],a:0,e:"Sec. 18.1.1 (Unit 5) and 4.1.3 (Unit 6) show divided differences in Newton’s interpolation (Eq. 18.12) and finite differences (Eq. 4.17)."},
  {t:"Data Requirements",q:"Which method does not require equally spaced points?",o:["Newton’s interpolation","Centered difference differentiation","Composite Simpson’s 1/3 rule","Trapezoidal rule"],a:0,e:"Sec. 18.1.3 (Unit 5) notes Newton’s polynomial handles unequally spaced points, unlike differentiation (Sec. 4.1.3) and integration (Sec. 21.2) methods."},
  {t:"Error Reduction",q:"Richardson extrapolation is used to improve accuracy in:",o:["Interpolation and differentiation","Differentiation and integration","Interpolation and integration","All three units"],a:1,e:"Sec. 23.2 (Unit 6) and 22.2.1 (Unit 7) apply extrapolation for differentiation (Eq. 23.8) and integration (Eq. 22.4), but not in Unit 5."},
  {t:"Application Workflow",q:"To estimate a parachutist’s acceleration at t=10, you would:",o:["Interpolate velocity, then differentiate","Differentiate position, then integrate","Integrate velocity, then interpolate","Use Simpson’s rule directly"],a:0,e:"Example 18.7 (Unit 5) interpolates velocity; Sec. 4.1.3 (Unit 6) suggests differentiating to get acceleration."}
];

function buildQuiz() {
  const container = document.createElement('div');
  qData.forEach((item, idx) => {
    const qDiv = document.createElement('div');
    qDiv.className = 'question';
    qDiv.innerHTML = `<h3>Q${idx+1}. ${item.t}</h3><p>${item.q}</p>`;
    const form = document.createElement('form');
    item.o.forEach((opt, i) => {
      const id = `q${idx}o${i}`;
      const label = document.createElement('label');
      label.innerHTML = `<input type="radio" name="q${idx}" id="${id}" value="${i}"> ${opt}`;
      form.appendChild(label);
    });
    const fb = document.createElement('div');
    fb.className = 'feedback';
    form.addEventListener('change', e => {
      if (fb.textContent) return; // already answered
      const chosen = parseInt(form.querySelector('input:checked').value, 10);
      form.querySelector('input:checked').parentNode.style.color = '#e06e16';
      if (chosen === item.a) {
        fb.textContent = 'Correct!';
        fb.classList.add('correct');
      } else {
        fb.textContent = `Incorrect. ${item.e}`;
        fb.classList.add('incorrect');
      }
      // disable inputs
      [...form.querySelectorAll('input')].forEach(r=>r.disabled = true);
    });
    qDiv.appendChild(form);
    qDiv.appendChild(fb);
    container.appendChild(qDiv);
  });
  document.body.appendChild(container);
}

document.addEventListener('DOMContentLoaded', buildQuiz);
</script>
</body>
</html>
